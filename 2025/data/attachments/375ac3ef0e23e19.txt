[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:418 scaling database to zero units
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:422 scaling database to three units
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s (waiting for exactly 3 units, current : 0)
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [executing] waiting: awaiting for cluster to start
  postgresql-k8s/1 [executing] waiting: awaiting for cluster to start
  postgresql-k8s/2 [executing] unknown: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [executing] waiting: awaiting for primary endpoint to be ready
  postgresql-k8s/1 [idle] waiting: awaiting for cluster to start
  postgresql-k8s/2 [idle] unknown: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [executing] waiting: awaiting for primary endpoint to be ready
  postgresql-k8s/1 [idle] waiting: awaiting for cluster to start
  postgresql-k8s/2 [idle] unknown: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [idle] waiting: awaiting for primary endpoint to be ready
  postgresql-k8s/1 [idle] waiting: awaiting for cluster to start
  postgresql-k8s/2 [idle] unknown: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] waiting: awaiting for cluster to start
  postgresql-k8s/2 [idle] unknown: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [executing] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] waiting: awaiting for cluster to start
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] maintenance: reinitialising replica
  postgresql-k8s/2 [idle] active: 
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [executing] active: 
  postgresql-k8s/1 [idle] waiting: awaiting for member to start
  postgresql-k8s/2 [idle] maintenance: reinitialising replica
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [idle] active: 
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] waiting: awaiting for member to start
[32mINFO    [0m juju.model:model.py:2957 Waiting for model:
  postgresql-k8s/0 [idle] active: Primary
  postgresql-k8s/1 [idle] active: 
  postgresql-k8s/2 [idle] active: 
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:426 waiting for the database service to start in all units
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:432 checking whether writes are increasing
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:436 checking whether all units are part of the same cluster
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-2 "HTTP/1.1 200 OK"
[32mINFO    [0m integration.ha_tests.test_self_healing:test_self_healing.py:445 checking whether no writes to the database were missed after stopping the writes
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-0 "HTTP/1.1 200 OK"
[32mINFO    [0m httpx:_client.py:1026 HTTP Request: GET https://10.1.0.67:16443/api/v1/namespaces/test/pods/postgresql-k8s-1 "HTTP/1.1 200 OK"
[32mINFO    [0m pytest_operator.plugin:plugin.py:791 Model status:

Model  Controller          Cloud/Region        Version  SLA          Timestamp
test   microk8s-localhost  microk8s/localhost  3.1.7    unsupported  02:02:47Z

App                  Version  Status  Scale  Charm                Channel  Rev  Address         Exposed  Message
postgresql-k8s       14.11    active      3  postgresql-k8s                  0  10.152.183.143  no       Primary
postgresql-test-app           active      1  postgresql-test-app  edge      76  10.152.183.192  no       received database credentials of the first database

Unit                    Workload  Agent  Address      Ports  Message
postgresql-k8s/0*       active    idle   10.1.253.19         Primary
postgresql-k8s/1        active    idle   10.1.253.20         
postgresql-k8s/2        active    idle   10.1.253.21         
postgresql-test-app/0*  active    idle   10.1.253.11         received database credentials of the first database

[32mINFO    [0m pytest_operator.plugin:plugin.py:797 Juju error logs:

unit-postgresql-k8s-2: 01:55:44 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: api connection broken unexpectedly
unit-postgresql-k8s-2: 01:55:44 ERROR juju.worker.caasunitterminationworker error while terminating unit: connection is shut down
unit-postgresql-k8s-2: 01:55:44 ERROR juju.worker.uniter resolver loop error: preparing operation "run update-status hook" for postgresql-k8s/2: getting unit payloads: connection is shut down
unit-postgresql-k8s-2: 01:55:44 ERROR juju.worker.uniter updating agent status: connection is shut down
unit-postgresql-k8s-2: 01:55:50 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b1b943] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-microk8s-localhost.svc.cluster.local": lookup controller-service.controller-microk8s-localhost.svc.cluster.local: i/o timeout
unit-postgresql-k8s-2: 01:55:57 ERROR juju.worker.dependency "api-caller" manifold worker returned unexpected error: [b1b943] "unit-postgresql-k8s-2" cannot open api: cannot resolve "controller-service.controller-microk8s-localhost.svc.cluster.local": lookup controller-service.controller-microk8s-localhost.svc.cluster.local: i/o timeout

[32mINFO    [0m pytest_operator.plugin:plugin.py:861 Forgetting main...